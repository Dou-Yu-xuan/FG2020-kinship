{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test', 'train', 'train_relationships.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract,Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import sqrt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_famillies_list = [\"F09\",\"F04\",\"F08\",\"F06\", \"F02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(familly_name):\n",
    "#     train_file_path = \"./input/train_relationships.csv\"\n",
    "#     train_folders_path = \"./input/train/\"\n",
    "    train_file_path = \"./input/train_pairs_new.xlsx\"\n",
    "    train_folders_path = \"./input/train_new/\"\n",
    "    val_famillies = familly_name\n",
    "\n",
    "    all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
    "    all_images=[x.replace('\\\\','/') for x in all_images]\n",
    "    train_images = [x for x in all_images if val_famillies not in x]\n",
    "    val_images = [x for x in all_images if val_famillies in x]\n",
    "\n",
    "    train_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "\n",
    "    for x in train_images:\n",
    "        train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "    val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "    for x in val_images:\n",
    "        val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "#     relationships = pd.read_excel(train_file_path)\n",
    "    relationships = pd.read_excel(train_file_path)\n",
    "    relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "    relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
    "\n",
    "    train = [x for x in relationships if val_famillies not in x[0]]\n",
    "    val = [x for x in relationships if val_famillies in x[0]]\n",
    "    return train, val, train_person_to_images_map, val_person_to_images_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_sqrt(x):\n",
    "    return keras.backend.sign(x) * keras.backend.sqrt(keras.backend.abs(x) + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return preprocess_input(img, version=2)\n",
    "\n",
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    input_1 = Input(shape=(224, 224, 3))\n",
    "    input_2 = Input(shape=(224, 224, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "\n",
    "    x1=GlobalMaxPool2D()(x1)\n",
    "    x2=GlobalAvgPool2D()(x2)\n",
    "    \n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    \n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    x5 = Multiply()([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x3, x4, x5])\n",
    "#     x = Dense(512, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.03)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.02)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00003))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00001))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0201 21:05:46.935994 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0201 21:05:47.471307 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0201 21:05:47.580016 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0201 21:05:47.698775 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0201 21:05:47.699772 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0201 21:06:02.172807 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0201 21:06:02.357894 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0201 21:06:05.431649 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0201 21:06:14.374181 16372 deprecation.py:506] From E:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0201 21:06:14.400114 16372 deprecation_wrapper.py:119] From E:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0201 21:06:14.406097 16372 deprecation.py:323] From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2048)         0           subtract_1[0][0]                 \n",
      "                                                                 subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 2048)         0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6144)         0           multiply_1[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          786560      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,347,841\n",
      "Trainable params: 24,294,721\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(n_val_famillies_list)):\n",
    "    train, val, train_person_to_images_map, val_person_to_images_map = get_train_val(val_famillies_list[i])\n",
    "    file_path = \"vgg_face_{}.h5\".format(i)\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.3, patience=30, verbose=1)\n",
    "#     reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.2, patience=20, verbose=1)   \n",
    "    callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "    history = model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), \n",
    "                                  use_multiprocessing=False,\n",
    "                                  validation_data=gen(val, val_person_to_images_map, batch_size=16), \n",
    "                                  epochs=66, verbose=2,\n",
    "                                  workers=1, callbacks=callbacks_list, \n",
    "                                  steps_per_epoch=300, validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b9cd3df3ee4c36934ecc5a6b556982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ab937ff3494690b5458b2ec3d2df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e90fc41c38443a5b0bf5b393064262d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc053279c53e446e8ab8ad62f9f8017b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df9509db10b4da7adb4ff7aaf06aee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46043eaf80f344e0bbbd1ae7d7ef8379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_path = \"./test/test-faces/\"\n",
    "\n",
    "submission = pd.read_csv('./test/test_pairs.csv')\n",
    "\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "preds_for_sub = np.zeros(submission.shape[0])\n",
    "\n",
    "for i in tqdm_notebook(range(n_val_famillies_list)):\n",
    "    file_path = f\"./vgg_face_{i}.h5\"\n",
    "    model.load_weights(file_path)\n",
    "    # Get the predictions\n",
    "    predictions = []\n",
    "\n",
    "    for batch in tqdm_notebook(chunker(submission.image_pairs.values)):\n",
    "        X1 = [x.split(\"-\")[0] for x in batch]\n",
    "        X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "        X2 = [x.split(\"-\")[1] for x in batch]\n",
    "        X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "        \n",
    "\n",
    "        pred = model.predict([X1, X2]).ravel().tolist()\n",
    "        predictions += pred\n",
    "        \n",
    "    preds_for_sub += np.array(predictions) / n_val_famillies_list\n",
    "\n",
    "submission['score'] = preds_for_sub\n",
    "submission.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
